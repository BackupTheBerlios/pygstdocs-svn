<?xml version="1.0" standalone="no"?>
<!DOCTYPE refentry PUBLIC "-//OASIS//DTD DocBook XML V4.1.2//EN" "http://www.oasis-open.org/docbook/xml/4.1.2/docbookx.dtd">

<refsect1>
  <para>The videomixer element makes it possible to mix different videostreams together. Here is a CLI example:
  </para>
  <synopsis>gst-launch-0.10 filesrc location=test.png ! pngdec ! alphacolor ! ffmpegcolorspace ! videobox border-alpha=0 alpha=0.5 top=-20 left=-200 ! \
	videomixer name=mix ! ffmpegcolorspace ! xvimagesink videotestsrc ! video/x-raw-yuv, width=320, height=240 ! mix.</synopsis>
 <para>
 You have to make a PNG image (100x100 px) to be able to run it. With the videobox element you can move the image
 around and adding more alpha channels.
 </para>
 <para>NEW COMPETITION! I can't figure out how to make a transparent alpha channel for the PNG in the pipeline above so if anyone
 makes it work the prize from example 3.2 will be given to this winner instead as the other one passed. TIA
</para>
<para>UPDATE! An anonymous dude solved the problem with an alphacolor element, many thanks man.
</para> 
<para>In the next example we take the now working Mpeg2-Player from example 3.2 and pump it with the stuff
shown above.
</para>
 <para>
<emphasis role="bold">Example 7.1</emphasis>
</para>
  <synopsis>#!/usr/bin/env python

import sys, os
import pygtk, gtk, gobject
import pygst
pygst.require("0.10")
import gst

class GTK_Main:
	
	def __init__(self):
		window = gtk.Window(gtk.WINDOW_TOPLEVEL)
		window.set_title("Mpeg2-Player")
		window.set_default_size(500, 400)
		window.connect("destroy", gtk.main_quit, "WM destroy")
		vbox = gtk.VBox()
		window.add(vbox)
		hbox = gtk.HBox()
		vbox.pack_start(hbox, False)
		self.entry = gtk.Entry()
		hbox.add(self.entry)
		self.button = gtk.Button("Start")
		hbox.pack_start(self.button, False)
		self.button.connect("clicked", self.start_stop)
		self.movie_window = gtk.DrawingArea()
		vbox.add(self.movie_window)
		window.show_all()
		
		self.player = gst.Pipeline("player")
		source = gst.element_factory_make("filesrc", "file-source")
		self.player.add(source)
		demuxer = gst.element_factory_make("mpegdemux", "demuxer")
		self.player.add(demuxer)
		demuxer.connect("pad-added", self.demuxer_callback)
		self.video_decoder = gst.element_factory_make("mpeg2dec", "video-decoder")
		self.player.add(self.video_decoder)
		png_decoder = gst.element_factory_make("pngdec", "png-decoder")
		self.player.add(png_decoder)
		png_source = gst.element_factory_make("filesrc", "png-source")
		self.player.add(png_source)
		png_source.set_property("location", "test.png")
		mixer = gst.element_factory_make("videomixer", "mixer")
		self.player.add(mixer)
		self.audio_decoder = gst.element_factory_make("mad", "audio-decoder")
		self.player.add(self.audio_decoder)
		audioconv = gst.element_factory_make("audioconvert", "converter")
		self.player.add(audioconv)
		audiosink = gst.element_factory_make("autoaudiosink", "audio-output")
		self.player.add(audiosink)
		videosink = gst.element_factory_make("autovideosink", "video-output")
		self.player.add(videosink)
		self.queuea = gst.element_factory_make("queue", "queuea")
		self.queuev = gst.element_factory_make("queue", "queuev")
		self.player.add(self.queuea)
		self.player.add(self.queuev)
		ffmpeg1 = gst.element_factory_make("ffmpegcolorspace", "ffmpeg1")
		self.player.add(ffmpeg1)
		ffmpeg2 = gst.element_factory_make("ffmpegcolorspace", "ffmpeg2")
		self.player.add(ffmpeg2)
		ffmpeg3 = gst.element_factory_make("ffmpegcolorspace", "ffmpeg3")
		self.player.add(ffmpeg3)
		videobox = gst.element_factory_make("videobox", "videobox")
		self.player.add(videobox)
		alphacolor = gst.element_factory_make("alphacolor", "alphacolor")
		self.player.add(alphacolor)
		
		gst.element_link_many(source, demuxer)
		gst.element_link_many(self.queuev, self.video_decoder, ffmpeg1, mixer, ffmpeg2, videosink)
		gst.element_link_many(png_source, png_decoder, alphacolor, ffmpeg3, videobox, mixer)
		gst.element_link_many(self.queuea, self.audio_decoder, audioconv, audiosink)
		
		bus = self.player.get_bus()
		bus.add_signal_watch()
		bus.enable_sync_message_emission()
		bus.connect("message", self.on_message)
		bus.connect("sync-message::element", self.on_sync_message)
		
	def start_stop(self, w):
		if self.button.get_label() == "Start":
			filepath = self.entry.get_text()
			if os.path.exists(filepath):
				self.button.set_label("Stop")
				self.player.get_by_name("file-source").set_property("location", filepath)
				self.player.set_state(gst.STATE_PLAYING)
		else:
			self.player.set_state(gst.STATE_NULL)
			self.button.set_label("Start")
						
	def on_message(self, bus, message):
		t = message.type
		if t == gst.MESSAGE_EOS:
			self.player.set_state(gst.STATE_NULL)
			self.button.set_label("Start")
		elif t == gst.MESSAGE_ERROR:
			err, debug = message.parse_error()
			print "Error: %s" % err, debug
			self.player.set_state(gst.STATE_NULL)
			self.button.set_label("Start")
	
	def on_sync_message(self, bus, message):
		if message.structure is None:
			return
		message_name = message.structure.get_name()
		if message_name == "prepare-xwindow-id":
			imagesink = message.src
			imagesink.set_property("force-aspect-ratio", True)
			imagesink.set_xwindow_id(self.movie_window.window.xid)
	
	def demuxer_callback(self, demuxer, pad):
		if pad.get_property("template").name_template == "video_%02d":
			dec_pad = self.queuev.get_pad("sink")
			pad.link(dec_pad)
		elif pad.get_property("template").name_template == "audio_%02d":
			dec_pad = self.queuea.get_pad("sink")
			pad.link(dec_pad)
		
GTK_Main()
gtk.gdk.threads_init()
gtk.main()
</synopsis>
 

</refsect1>


